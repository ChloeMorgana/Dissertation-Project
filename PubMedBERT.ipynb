{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Loading of DrugProt dataset\n",
        "\n",
        "Downloading and unzipping file"
      ],
      "metadata": {
        "id": "XEVZhcw6vcub"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXtcGw7lujGS",
        "outputId": "77ce3111-5278-42bb-bbd9-11feac2d8b0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-11 14:50:55--  https://zenodo.org/record/5042151/files/drugprot-gs-training-development.zip\n",
            "Resolving zenodo.org (zenodo.org)... 188.184.117.155\n",
            "Connecting to zenodo.org (zenodo.org)|188.184.117.155|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3796908 (3.6M) [application/octet-stream]\n",
            "Saving to: ‘drugprot-gs-training-development.zip.1’\n",
            "\n",
            "drugprot-gs-trainin 100%[===================>]   3.62M  22.7MB/s    in 0.2s    \n",
            "\n",
            "2022-11-11 14:50:55 (22.7 MB/s) - ‘drugprot-gs-training-development.zip.1’ saved [3796908/3796908]\n",
            "\n",
            "Archive:  drugprot-gs-training-development.zip\n",
            "replace drugprot-gs-training-development/README.pdf? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace drugprot-gs-training-development/development/drugprot_development_relations.tsv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace drugprot-gs-training-development/development/drugprot_development_entities.tsv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace drugprot-gs-training-development/development/drugprot_development_abstracs.tsv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!wget https://zenodo.org/record/5042151/files/drugprot-gs-training-development.zip\n",
        "!unzip drugprot-gs-training-development.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combining all three files together."
      ],
      "metadata": {
        "id": "BlEsiDFNyVK2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loadDrugProt(abstracts_filename, entities_filename, relations_filename):\n",
        "\n",
        "  docs = {}\n",
        "\n",
        "  # Load the title/abstracts text in as documents\n",
        "  with open(abstracts_filename, encoding='utf8') as f:\n",
        "    for lineno,line in enumerate(f):\n",
        "      split = line.strip('\\n').split('\\t')\n",
        "      assert len(split) == 3, f\"Expected 3 columns but got {len(split)} on line {lineno+1}\"\n",
        "      pubmed_id, title, abstract = split\n",
        "      pubmed_id = int(pubmed_id)\n",
        "\n",
        "      combined_text = title + '\\n' + abstract\n",
        "      docs[pubmed_id] = {'pubmed_id':pubmed_id, 'text':combined_text, 'entities':{}, 'relations':[]}\n",
        "\n",
        "  # Load the entities and match them up with the documents\n",
        "  with open(entities_filename, encoding='utf8') as f:\n",
        "    for lineno,line in enumerate(f):\n",
        "      split = line.strip('\\n').split('\\t')\n",
        "      assert len(split) == 6, f\"Expected 6 columns but got {len(split)} on line {lineno+1}\"\n",
        "      pubmed_id, entity_id, entity_type, start_coord, end_coord, entity_text = split\n",
        "\n",
        "      pubmed_id = int(pubmed_id)\n",
        "      start_coord = int(start_coord)\n",
        "      end_coord = int(end_coord)\n",
        "\n",
        "      assert pubmed_id in docs, f\"Did not find matching document for pubmed_id={pubmed_id}\"\n",
        "      doc = docs[pubmed_id]\n",
        "\n",
        "      assert doc['text'][start_coord:end_coord] == entity_text, f\"Text for entity with coords {start_coord}:{end_coord} in document (pubmed_id={pubmed_id} does not match expected. 'f{doc['text'][start_coord:end_coord]}' != '{entity_text}'\"\n",
        "\n",
        "      entity = {'type':entity_type, 'start':start_coord, 'end':end_coord, 'text':entity_text}\n",
        "      doc['entities'][entity_id] = entity\n",
        "\n",
        "  if relations_filename is not None:\n",
        "    # Load the relations and match them up with the entities in the corresponding document\n",
        "    with open(relations_filename, encoding='utf8') as f:\n",
        "      for lineno,line in enumerate(f):\n",
        "        split = line.strip('\\n').split('\\t')\n",
        "        assert len(split) == 4, f\"Expected 4 columns but got {len(split)} on line {lineno+1}\"\n",
        "\n",
        "        pubmed_id, relation_type, arg1, arg2 = split\n",
        "\n",
        "        pubmed_id = int(pubmed_id)\n",
        "        assert arg1.startswith('Arg1:'), f\"Relation argument should start with 'Arg1:'. Got: {arg1}\"\n",
        "        assert arg2.startswith('Arg2:'), f\"Relation argument should start with 'Arg2:'. Got: {arg2}\"\n",
        "\n",
        "        # Remove arg1/arg2 from text\n",
        "        arg1 = arg1.split(':')[1]\n",
        "        arg2 = arg2.split(':')[1]\n",
        "\n",
        "        assert pubmed_id in docs, f\"Did not find matching document for pubmed_id={pubmed_id}\"\n",
        "        doc = docs[pubmed_id]\n",
        "\n",
        "        assert arg1 in doc['entities'], f\"Couldn't find entity with id={arg1} in document with pubmed_id={pubmed_id}\"\n",
        "        assert arg2 in doc['entities'], f\"Couldn't find entity with id={arg2} in document with pubmed_id={pubmed_id}\"\n",
        "\n",
        "        relation = {'type':relation_type,'arg1':arg1,'arg2':arg2}\n",
        "        doc['relations'].append(relation)\n",
        "\n",
        "  # Convert the dictionary of documents (indexed by pubmed_id) into a simpler dictionary\n",
        "  docs = sorted(docs.values(), key=lambda x:x['pubmed_id'])\n",
        "\n",
        "  return docs"
      ],
      "metadata": {
        "id": "Jnq0pnCUvtPI"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Applying function to dataset"
      ],
      "metadata": {
        "id": "rmXTTkBLyk4Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docs = loadDrugProt('drugprot-gs-training-development/training/drugprot_training_abstracs.tsv',\n",
        "                    'drugprot-gs-training-development/training/drugprot_training_entities.tsv',\n",
        "                    'drugprot-gs-training-development/training/drugprot_training_relations.tsv')"
      ],
      "metadata": {
        "id": "yAemM9gmyG7F"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation of doc structure\n"
      ],
      "metadata": {
        "id": "hsBqNeznyrJC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "search = [ d for i,d in enumerate(docs) if d['pubmed_id'] == 1280065]\n",
        "assert len(search) == 1, \"Something went wrong and couldn't find the document we want\"\n",
        "\n",
        "doc = search[0]\n",
        "doc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYt1O1bLyKK8",
        "outputId": "591c0d6c-068b-40d3-eacf-de1b82730acf"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'pubmed_id': 1280065,\n",
              " 'text': 'Analysis of plasmin binding and urokinase activation of plasminogen bound to the Heymann nephritis autoantigen, gp330.\\nPreviously, we demonstrated that the Heymann nephritis autoantigen, gp330, can serve as a receptor site for plasminogen. This binding was not significantly inhibited by the lysine analogue epsilon-amino caproic acid (EACA), indicating that plasminogen binding was not just through lysine binding sites as suggested for other plasminogen binding sites. We now report that once plasminogen is bound to gp330, it can be converted to its active form of plasmin by urokinase. This conversion of plasminogen to plasmin proceeds at a faster rate when plasminogen is first prebound to gp330. Although there is a proportional increase in the Vmax of the urokinase-catalyzed reaction with increasing gp330 concentrations, no change in Km was observed. Once activated, plasmin remains bound to gp330 in an active state capable of cleaving the chromogenic tripeptide, S-2251. The binding of plasmin to gp330 did not significantly change its enzymatic activity; however, gp330 did have a stabilizing effect on plasmin activity at 37 degrees C. While bound to gp330, plasmin is protected from inactivation by its natural inhibitor alpha 2-antiplasmin. The binding of plasmin to gp330 as analyzed by ELISA was shown to be time dependent, reversible, saturable, and specific for gp330. Inhibition of binding of both plasminogen and plasmin to gp330 by benzamidine was similar, although EACA inhibited the binding of plasmin to gp330 slightly more than the binding of plasminogen to gp330. These results indicate that the binding of plasminogen to gp330 serves as an effective means of increasing the rate of plasmin production on the glomerular and tubular epithelial cell surface while protecting the active plasmin from natural inhibitors.',\n",
              " 'entities': {'T1': {'type': 'CHEMICAL',\n",
              "   'start': 1455,\n",
              "   'end': 1466,\n",
              "   'text': 'benzamidine'},\n",
              "  'T2': {'type': 'CHEMICAL', 'start': 1489, 'end': 1493, 'text': 'EACA'},\n",
              "  'T3': {'type': 'CHEMICAL', 'start': 292, 'end': 298, 'text': 'lysine'},\n",
              "  'T4': {'type': 'CHEMICAL',\n",
              "   'start': 308,\n",
              "   'end': 334,\n",
              "   'text': 'epsilon-amino caproic acid'},\n",
              "  'T5': {'type': 'CHEMICAL', 'start': 336, 'end': 340, 'text': 'EACA'},\n",
              "  'T6': {'type': 'CHEMICAL', 'start': 400, 'end': 406, 'text': 'lysine'},\n",
              "  'T7': {'type': 'GENE-Y', 'start': 1165, 'end': 1170, 'text': 'gp330'},\n",
              "  'T8': {'type': 'GENE-Y', 'start': 1172, 'end': 1179, 'text': 'plasmin'},\n",
              "  'T9': {'type': 'GENE-Y', 'start': 227, 'end': 238, 'text': 'plasminogen'},\n",
              "  'T10': {'type': 'GENE-Y',\n",
              "   'start': 1236,\n",
              "   'end': 1255,\n",
              "   'text': 'alpha 2-antiplasmin'},\n",
              "  'T11': {'type': 'GENE-Y', 'start': 1272, 'end': 1279, 'text': 'plasmin'},\n",
              "  'T12': {'type': 'GENE-Y', 'start': 1283, 'end': 1288, 'text': 'gp330'},\n",
              "  'T13': {'type': 'GENE-Y', 'start': 1382, 'end': 1387, 'text': 'gp330'},\n",
              "  'T14': {'type': 'GENE-Y', 'start': 1419, 'end': 1430, 'text': 'plasminogen'},\n",
              "  'T15': {'type': 'GENE-Y', 'start': 1435, 'end': 1442, 'text': 'plasmin'},\n",
              "  'T16': {'type': 'GENE-Y', 'start': 1446, 'end': 1451, 'text': 'gp330'},\n",
              "  'T17': {'type': 'GENE-Y', 'start': 1519, 'end': 1526, 'text': 'plasmin'},\n",
              "  'T18': {'type': 'GENE-Y', 'start': 1530, 'end': 1535, 'text': 'gp330'},\n",
              "  'T19': {'type': 'GENE-Y', 'start': 1570, 'end': 1581, 'text': 'plasminogen'},\n",
              "  'T20': {'type': 'GENE-Y', 'start': 1585, 'end': 1590, 'text': 'gp330'},\n",
              "  'T21': {'type': 'GENE-Y', 'start': 1635, 'end': 1646, 'text': 'plasminogen'},\n",
              "  'T22': {'type': 'GENE-Y', 'start': 1650, 'end': 1655, 'text': 'gp330'},\n",
              "  'T23': {'type': 'GENE-Y', 'start': 1711, 'end': 1718, 'text': 'plasmin'},\n",
              "  'T24': {'type': 'GENE-Y', 'start': 1812, 'end': 1819, 'text': 'plasmin'},\n",
              "  'T25': {'type': 'GENE-Y', 'start': 359, 'end': 370, 'text': 'plasminogen'},\n",
              "  'T26': {'type': 'GENE-Y', 'start': 444, 'end': 455, 'text': 'plasminogen'},\n",
              "  'T27': {'type': 'GENE-Y', 'start': 495, 'end': 506, 'text': 'plasminogen'},\n",
              "  'T28': {'type': 'GENE-Y',\n",
              "   'start': 156,\n",
              "   'end': 185,\n",
              "   'text': 'Heymann nephritis autoantigen'},\n",
              "  'T29': {'type': 'GENE-Y', 'start': 519, 'end': 524, 'text': 'gp330'},\n",
              "  'T30': {'type': 'GENE-Y', 'start': 568, 'end': 575, 'text': 'plasmin'},\n",
              "  'T31': {'type': 'GENE-Y', 'start': 579, 'end': 588, 'text': 'urokinase'},\n",
              "  'T32': {'type': 'GENE-Y', 'start': 609, 'end': 620, 'text': 'plasminogen'},\n",
              "  'T33': {'type': 'GENE-Y', 'start': 624, 'end': 631, 'text': 'plasmin'},\n",
              "  'T34': {'type': 'GENE-Y', 'start': 663, 'end': 674, 'text': 'plasminogen'},\n",
              "  'T35': {'type': 'GENE-Y', 'start': 696, 'end': 701, 'text': 'gp330'},\n",
              "  'T36': {'type': 'GENE-Y', 'start': 764, 'end': 773, 'text': 'urokinase'},\n",
              "  'T37': {'type': 'GENE-Y', 'start': 187, 'end': 192, 'text': 'gp330'},\n",
              "  'T38': {'type': 'GENE-Y', 'start': 809, 'end': 814, 'text': 'gp330'},\n",
              "  'T39': {'type': 'GENE-Y', 'start': 877, 'end': 884, 'text': 'plasmin'},\n",
              "  'T40': {'type': 'GENE-Y', 'start': 902, 'end': 907, 'text': 'gp330'},\n",
              "  'T41': {'type': 'GENE-Y', 'start': 998, 'end': 1005, 'text': 'plasmin'},\n",
              "  'T42': {'type': 'GENE-Y', 'start': 1009, 'end': 1014, 'text': 'gp330'},\n",
              "  'T43': {'type': 'GENE-Y', 'start': 1077, 'end': 1082, 'text': 'gp330'},\n",
              "  'T44': {'type': 'GENE-Y', 'start': 1116, 'end': 1123, 'text': 'plasmin'},\n",
              "  'T45': {'type': 'GENE-Y', 'start': 112, 'end': 117, 'text': 'gp330'},\n",
              "  'T46': {'type': 'GENE-Y', 'start': 12, 'end': 19, 'text': 'plasmin'},\n",
              "  'T47': {'type': 'GENE-Y', 'start': 32, 'end': 41, 'text': 'urokinase'},\n",
              "  'T48': {'type': 'GENE-Y', 'start': 56, 'end': 67, 'text': 'plasminogen'},\n",
              "  'T49': {'type': 'GENE-Y',\n",
              "   'start': 81,\n",
              "   'end': 110,\n",
              "   'text': 'Heymann nephritis autoantigen'}},\n",
              " 'relations': [{'type': 'INHIBITOR', 'arg1': 'T1', 'arg2': 'T14'},\n",
              "  {'type': 'INHIBITOR', 'arg1': 'T1', 'arg2': 'T15'},\n",
              "  {'type': 'DIRECT-REGULATOR', 'arg1': 'T1', 'arg2': 'T16'},\n",
              "  {'type': 'INHIBITOR', 'arg1': 'T2', 'arg2': 'T17'},\n",
              "  {'type': 'DIRECT-REGULATOR', 'arg1': 'T2', 'arg2': 'T18'},\n",
              "  {'type': 'INHIBITOR', 'arg1': 'T2', 'arg2': 'T19'},\n",
              "  {'type': 'DIRECT-REGULATOR', 'arg1': 'T2', 'arg2': 'T20'}]}"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Total number of relations"
      ],
      "metadata": {
        "id": "SvJVGoiznqJs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num = 0\n",
        "for doc in docs:\n",
        "  num += len(doc['relations'])\n",
        "\n",
        "print(num)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YaUZTJ6Qntfq",
        "outputId": "2e583260-d44b-44aa-aaee-7b2a0ad0684d"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17288\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoding Step"
      ],
      "metadata": {
        "id": "wuvPifsbVAI2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install torch\n",
        "!pip install transformers\n",
        "!pip install segtok\n",
        "\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import torch\n",
        "from segtok.segmenter import split_single"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zt-G3qMF6S6z",
        "outputId": "d3240a4b-3a54-40ca-82e1-a63790bdd47f"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.24.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: segtok in /usr/local/lib/python3.7/dist-packages (1.5.11)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from segtok) (2022.6.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding in start and end entity tags to biomedical text, e.g. [E1] CHEMICAL [/E1] and [E2] GENE [/E2]"
      ],
      "metadata": {
        "id": "DjiNDFJvgckl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def isRelation(doc, key):\n",
        "  relations = doc['relations']\n",
        "  entities = doc['entities'].keys()\n",
        "  for r in relations:\n",
        "    if (key == r['arg1']) or (key == r['arg2']):\n",
        "      return True\n",
        "  return False"
      ],
      "metadata": {
        "id": "ejFWUmo2hGJi"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def addEntityTags(docs):\n",
        "  for doc in docs:\n",
        "    str = ''\n",
        "    index = 0\n",
        "    entity_dict = {}\n",
        "    n = 1\n",
        "    keys = doc['entities'].keys()\n",
        "    key_list = sorted(keys, key= lambda x: (doc['entities'][x]['start']))\n",
        "    for k in key_list:\n",
        "      start = doc['entities'][k]['start']\n",
        "      end = doc['entities'][k]['end']\n",
        "      name = doc['entities'][k]['text']\n",
        "      if isRelation(doc,k):\n",
        "        if entity_dict.get(name) is not None:\n",
        "          i = entity_dict[name]\n",
        "          str += doc['text'][index:start] + f'[E{i}] ' + doc['text'][start:end] + f' [/E{i}]'\n",
        "          index = end\n",
        "        else:\n",
        "          entity_dict[name] = n\n",
        "          i = entity_dict[name]\n",
        "          str += doc['text'][index:start] + f'[E{i}] ' + doc['text'][start:end] + f' [/E{i}]'\n",
        "          n+=1\n",
        "          index = end\n",
        "    doc['tagged_text'] = str \n",
        "\n",
        "addEntityTags(docs)\n",
        "print(docs[0]['tagged_text'])\n",
        "      "
      ],
      "metadata": {
        "id": "a7MjEIFqgiiC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a919aec-5d94-460f-c1d9-f085d8897ce4"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analysis of plasmin binding and urokinase activation of plasminogen bound to the Heymann nephritis autoantigen, gp330.\n",
            "Previously, we demonstrated that the Heymann nephritis autoantigen, gp330, can serve as a receptor site for plasminogen. This binding was not significantly inhibited by the lysine analogue epsilon-amino caproic acid (EACA), indicating that plasminogen binding was not just through lysine binding sites as suggested for other plasminogen binding sites. We now report that once plasminogen is bound to gp330, it can be converted to its active form of plasmin by urokinase. This conversion of plasminogen to plasmin proceeds at a faster rate when plasminogen is first prebound to gp330. Although there is a proportional increase in the Vmax of the urokinase-catalyzed reaction with increasing gp330 concentrations, no change in Km was observed. Once activated, plasmin remains bound to gp330 in an active state capable of cleaving the chromogenic tripeptide, S-2251. The binding of plasmin to gp330 did not significantly change its enzymatic activity; however, gp330 did have a stabilizing effect on plasmin activity at 37 degrees C. While bound to gp330, plasmin is protected from inactivation by its natural inhibitor alpha 2-antiplasmin. The binding of plasmin to gp330 as analyzed by ELISA was shown to be time dependent, reversible, saturable, and specific for gp330. Inhibition of binding of both [E1] plasminogen [/E1] and [E2] plasmin [/E2] to [E3] gp330 [/E3] by [E4] benzamidine [/E4] was similar, although [E5] EACA [/E5] inhibited the binding of [E2] plasmin [/E2] to [E3] gp330 [/E3] slightly more than the binding of [E1] plasminogen [/E1] to [E3] gp330 [/E3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reducing the text only to sentences potentially containing relations between chemicals and genes:"
      ],
      "metadata": {
        "id": "4ikJplM-cXqU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def relevantText():\n",
        "  texts = [doc['tagged_text'] for doc in docs]\n",
        "\n",
        "  split_text = []\n",
        "  target_text = []\n",
        "\n",
        "  for d in texts:\n",
        "    split_text += split_single(d)\n",
        "\n",
        "  for s in split_text:\n",
        "    if '[/E' in s:\n",
        "      target_text.append(s)\n",
        "\n",
        "  return target_text\n",
        "\n",
        "target_text = relevantText()\n",
        "print(target_text[:5])"
      ],
      "metadata": {
        "id": "x0ps_RaP3wMU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b17839b-7a36-4d23-bf7c-e25752a34c02"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Inhibition of binding of both [E1] plasminogen [/E1] and [E2] plasmin [/E2] to [E3] gp330 [/E3] by [E4] benzamidine [/E4] was similar, although [E5] EACA [/E5] inhibited the binding of [E2] plasmin [/E2] to [E3] gp330 [/E3] slightly more than the binding of [E1] plasminogen [/E1] to [E3] gp330 [/E3]', 'A cDNA encoding the complete [E1] amino acid [/E1] sequence of [E2] aminoacylase 1 [/E2] ([E3] N-acylamino acid aminohydrolase [/E3], [E4] ACY-1 [/E4]) [[E5] EC 3.5.1.14 [/E5]], a dimeric [E6] metalloprotein [/E6] having two Zn2+ in the molecule, which catalyzes the deacylation of [E7] N-acylated L-amino acids [/E7] except L-aspartic acid, has been isolated from porcine kidney lambda gt10 cDNA library and sequenced.', 'From sequence analysis of the cDNA and the [E8] N [/E8]- and [E9] C [/E9]-terminal [E1] amino acid [/E1] analyses of the purified protein, it is deduced that [E10] porcine kidney ACY-1 [/E10] consists of two identical subunits (M(r) 45,260), each of which consists of a single chain of 406 [E11] amino acids [/E11] with [E12] acetylalanine [/E12] at the [E8] N [/E8]-terminus.', 'The [E1] amino acid [/E1] sequence deduced from the [E13] nucleotide [/E13] sequence of the cDNA from porcine liver was identical to that deduced for [E10] porcine kidney ACY-1 [/E10].', 'Comparison of the [E1] amino acid [/E1] sequence of [E14] porcine ACY-1 [/E14] with those of other [E15] Zn2+-binding metalloenzymes [/E15]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are around 17288 total relations, therefore there some sentences that contain entities but don't actually contain a relation"
      ],
      "metadata": {
        "id": "jI2VTA9Po-a9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(target_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zb4HIf7ebZdo",
        "outputId": "37f5c813-2944-4587-ae21-1da22055eb26"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6709\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embedding Step\n",
        "\n",
        "Loading pre-trained PubMedBERT model + tokenizer"
      ],
      "metadata": {
        "id": "BXYgjLzmG2DT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertModel.from_pretrained(\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\",\n",
        "                                  output_hidden_states = True,\n",
        "                                  )\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\") "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtHyA7DTG40c",
        "outputId": "c6efacf3-1066-4f03-e1d5-350ff6c59615"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding more tags and tokenising input"
      ],
      "metadata": {
        "id": "eFzXfZX-X3D8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bert_text_prep(text, tokenizer):\n",
        "\n",
        "  #CLS lets BERT know when start of sentence begins, SEP indicates start of second sentence.\n",
        "  marked_text = \"[CLS]\" + text + \"[SEP]\"\n",
        "\n",
        "  #Tokenizes text\n",
        "  tokenized_text = tokenizer.tokenize(marked_text)\n",
        "\n",
        "  #Converts to ids\n",
        "  indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "\n",
        "  segments_ids = [1]*len(indexed_tokens)\n",
        "\n",
        "  # Converts inputs to tensors\n",
        "  tokens_tensor = torch.tensor([indexed_tokens])\n",
        "  segments_tensors = torch.tensor([segments_ids])\n",
        "\n",
        "  return tokenized_text, tokens_tensor, segments_tensors"
      ],
      "metadata": {
        "id": "8LWbqPbBL6TD"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting input into embeddings"
      ],
      "metadata": {
        "id": "PMth1UIhX6a5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_bert_embeddings(tokens_tensor, segments_tensors, model):\n",
        "  with torch.no_grad():\n",
        "    outputs = model(tokens_tensor, segments_tensors)\n",
        "    hidden_states = outputs[2][1:]\n",
        "\n",
        "  token_embeddings = hidden_states[-1]\n",
        "  #Collapsing tensor into 1 dimension\n",
        "  token_embeddings = torch.squeeze(token_embeddings, dim=0)\n",
        "  #converting tensors to lists\n",
        "  list_token_embeddings = [token_embed.tolist() for token_embed in token_embeddings]\n",
        "\n",
        "  return list_token_embeddings"
      ],
      "metadata": {
        "id": "-OnSsiEiOQrM"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting CLS embeddings for each sentence\n",
        "\n"
      ],
      "metadata": {
        "id": "SDwF0f2a3rHE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = target_text[:5]\n",
        "cls_embeddings = []\n",
        "\n",
        "for text in test:\n",
        "    tokenized_text, tokens_tensor, segments_tensors = bert_text_prep(text, tokenizer)\n",
        "    list_token_embeddings = get_bert_embeddings(tokens_tensor, segments_tensors, model)\n",
        "    cls_embeddings.append(list_token_embeddings[0])\n",
        "\n",
        "print(len(cls_embeddings))"
      ],
      "metadata": {
        "id": "tXoMT_blWrhG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "902dcb55-3646-4ed7-bca5-ce6248632a29"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification Step"
      ],
      "metadata": {
        "id": "E4CWwTfCcIqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ijHn5tYH2ecP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Establishing the relation labels"
      ],
      "metadata": {
        "id": "4lZZpVkhdC7I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = list(set([r['type'] for doc in docs for r in doc['relations']]))"
      ],
      "metadata": {
        "id": "QklH7WB6ZaWE"
      },
      "execution_count": 61,
      "outputs": []
    }
  ]
}